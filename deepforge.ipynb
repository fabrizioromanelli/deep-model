{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 12:21:28.203222: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-11 12:21:28.283337: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-11 12:21:29.894158: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-11 12:21:29.897596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-11 12:21:29.897644: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-11 12:21:30.420836: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-11 12:21:30.420967: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-11 12:21:30.420975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-11 12:21:30.421000: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-11 12:21:30.421025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1585 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Jupyter notebook for testing deepforge library\n",
    "# author: Fabrizio Romanelli\n",
    "# email : fabrizio.romanelli@gmail.com\n",
    "# date  : 04/10/2023\n",
    "\n",
    "# Import the deepforge library\n",
    "import deepforge as df\n",
    "\n",
    "# Initialize the environment\n",
    "df.initialize(CPU=20, GPU=1, VERBOSE='2', NPARRAYS=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple DNN example\n",
    "import numpy as np\n",
    "\n",
    "# Make an instance of a multivariate DNN\n",
    "mDnn = df.multivariateDNN(name=\"Simple DNN\", inputN=1)\n",
    "\n",
    "# Set inputs, inner layers and out layers\n",
    "mDnn.setInputs([{'shape': (2,), 'name': 'Input layer'}])\n",
    "mDnn.setLayers([[{'units': 16, 'activation': 'elu'}, {'units': 16, 'activation': 'elu'}, {'units': 16, 'activation': 'elu'}, {'units': 3, 'activation': 'linear'}]])\n",
    "mDnn.setOutLayers([{'units': 1, 'activation': 'linear'}])\n",
    "\n",
    "# Configure the model\n",
    "mDnn.setModelConfiguration(optimizer='adam', loss='mse')\n",
    "\n",
    "# Build the model and print the summary\n",
    "mDnn.build()\n",
    "mDnn.summary()\n",
    "\n",
    "# Train the model\n",
    "x1 = np.array([2,3,5,6,7], dtype=np.float32)\n",
    "x2 = np.array([1,2,4,5,6], dtype=np.float32)\n",
    "X1 = np.array([x1,x2], dtype=np.float32).T\n",
    "y  = np.array([3,4,6,7,8], dtype=np.float32)\n",
    "\n",
    "mDnn.fit(x=[X1], y=y, epochs=20, shuffle=True, verbose=0)\n",
    "\n",
    "# Save the model\n",
    "mDnn.save('simpleDNN',tflite=False)\n",
    "\n",
    "# Make a prediction with the model\n",
    "x1 = np.array([8], dtype=np.float32)\n",
    "x2 = np.array([7], dtype=np.float32)\n",
    "X1 = np.array([x1,x2], dtype=np.float32).T\n",
    "y = mDnn.predict([X1])\n",
    "print(y.numpy())\n",
    "\n",
    "# Load the model\n",
    "mDnnCopy = df.multivariateDNN(name=\"simple DNN 2\")\n",
    "mDnnCopy.load(\"simpleDNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN with 2 input layers and custom loss function example\n",
    "import numpy as np\n",
    "from keras.losses import MeanSquaredError\n",
    "\n",
    "# Define a custom loss function\n",
    "def custom_loss(y_true, y_pred):\n",
    "  mse = MeanSquaredError()\n",
    "  return mse(y_true, y_pred)\n",
    "\n",
    "# Make an instance of a multivariate DNN\n",
    "mDnn2 = df.multivariateDNN(name=\"multivariate DNN\", inputN=2)\n",
    "\n",
    "# Set inputs, inner layers and out layers\n",
    "mDnn2.setInputs([{'shape': (2,), 'name': 'inputLayer1'}, {'shape': (2,), 'name': 'inputLayer2'}])\n",
    "\n",
    "innerLayers = [[{'units': 32, 'activation': 'elu'}, {'units': 16, 'activation': 'elu'}, {'units': 8, 'activation': 'elu'}, {'units': 3, 'activation': 'linear'}]]\n",
    "innerLayers.append([{'units': 32, 'activation': 'elu'}, {'units': 16, 'activation': 'elu'}, {'units': 8, 'activation': 'elu'}, {'units': 3, 'activation': 'linear'}])\n",
    "mDnn2.setLayers(innerLayers)\n",
    "\n",
    "outputLayers = [{'units': 32, 'activation': 'elu'}, {'units': 1, 'activation': 'linear'}]\n",
    "mDnn2.setOutLayers(outputLayers)\n",
    "\n",
    "# Configure the model\n",
    "mDnn2.setModelConfiguration(optimizer='adam', loss=custom_loss)\n",
    "\n",
    "# Build the model and print the summary\n",
    "mDnn2.build()\n",
    "mDnn2.summary()\n",
    "\n",
    "# Train the model\n",
    "x1 = np.array([0.2,0.3,0.5,0.6,0.7], dtype=np.float32)\n",
    "x2 = np.array([1.1,1.2,1.4,1.5,1.6], dtype=np.float32)\n",
    "X1 = np.array([x1,x2], dtype=np.float32).T\n",
    "x3 = np.array([0.2,0.3,0.5,0.6,0.7], dtype=np.float32)\n",
    "x4 = np.array([1.1,1.2,1.4,1.5,1.6], dtype=np.float32)\n",
    "X2 = np.array([x3,x4], dtype=np.float32).T\n",
    "y  = np.array([3.0,4.0,6.0,7.0,8.0], dtype=np.float32)\n",
    "\n",
    "mDnn2.fit(x=[X1,X2], y=y, epochs=50, shuffle=True, verbose=0)\n",
    "\n",
    "# Save the model\n",
    "mDnn2.save('multivariateDNN',tflite=False)\n",
    "\n",
    "# Make a prediction with the model\n",
    "x1 = np.array([0.4], dtype=np.float32)\n",
    "x2 = np.array([1.3], dtype=np.float32)\n",
    "X1 = np.array([x1,x2], dtype=np.float32).T\n",
    "x3 = np.array([0.4], dtype=np.float32)\n",
    "x4 = np.array([1.3], dtype=np.float32)\n",
    "X2 = np.array([x3,x4], dtype=np.float32).T\n",
    "y = mDnn2.predict([X1,X2])\n",
    "print(y.numpy())\n",
    "\n",
    "# Load the model with the custom loss function\n",
    "mDnn2Copy = df.multivariateDNN(name=\"multivariate DNN 2\")\n",
    "mDnn2Copy.load(\"multivariateDNN\", custom_objects = {'custom_loss': custom_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Neural Network example with MNIST dataset training and validation\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Make an instance of a CNN\n",
    "cnn = df.CNN(name=\"Simple CNN\", inputN=1)\n",
    "\n",
    "# Set inputs, inner layers and out layers\n",
    "cnn.setInputs([{'shape': (28, 28, 1), 'name': 'Input Layer'}])\n",
    "cnn.setConvLayers([[{'filters': 32, 'kernel_size': (3, 3), 'activation': 'relu'},{'filters': 64, 'kernel_size': (3, 3), 'activation': 'relu'},{'filters': 64, 'kernel_size': (3, 3), 'activation': 'relu'}]])\n",
    "cnn.setPoolLayers([[{'pool_size': (2,2)},{'pool_size': (2,2)}]])\n",
    "cnn.setOutLayers([{'units': 64, 'activation': 'relu'},{'units': 10, 'activation': 'softmax'}])\n",
    "\n",
    "# Configure the model\n",
    "cnn.setModelConfiguration(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Build the model and print the summary\n",
    "cnn.build()\n",
    "cnn.summary()\n",
    "\n",
    "# Load the MNIST dataset and preprocess it\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') / 255\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Fit the model\n",
    "cnn.fit(x=train_images, y=train_labels, epochs=5, batch_size=64)\n",
    "\n",
    "# Get the Keras model and run a test to evaluate accuracy\n",
    "cnnModel = cnn.getModel()\n",
    "\n",
    "test_loss, test_acc = cnnModel.evaluate(test_images, test_labels)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50ca6beb359c45098690b56dc2734b3d52d066029652770f8ebff3a62c9c1e26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
